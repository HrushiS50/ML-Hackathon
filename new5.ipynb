{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images mapped: 100\n",
      "Successfully loaded images: 100\n",
      "Skipped images: 0\n",
      "      entity_value  entity_number entity_unit\n",
      "0       500.0 gram        500.000        gram\n",
      "1          1.0 cup          1.000         cup\n",
      "2       0.709 gram          0.709        gram\n",
      "3       0.709 gram          0.709        gram\n",
      "4   1400 milligram       1400.000   milligram\n",
      "..             ...            ...         ...\n",
      "95       49.0 watt         49.000        watt\n",
      "96   500 milligram        500.000   milligram\n",
      "97   500 milligram        500.000   milligram\n",
      "98       16.0 gram         16.000        gram\n",
      "99      8 kilogram          8.000    kilogram\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "['image_link', 'group_id', 'entity_value', 'Image', 'Image_Arrays', 'entity_number', 'entity_name_item_volume', 'entity_name_item_weight', 'entity_name_voltage', 'entity_name_wattage', 'entity_unit_cubic', 'entity_unit_cup', 'entity_unit_gallon', 'entity_unit_gram', 'entity_unit_kilogram', 'entity_unit_milligram', 'entity_unit_millilitre', 'entity_unit_ounce', 'entity_unit_pound', 'entity_unit_volt', 'entity_unit_watt']\n",
      "Shape of train_features: (100, 115)\n",
      "Type of train_features: <class 'numpy.ndarray'>\n",
      "Shape of train_features: (100, 115)\n",
      "NaNs in train_features: False\n",
      "Infs in train_features: False\n",
      "Mean Squared Error for entity_number: 0.0023591077070458993\n",
      "Accuracy for entity_unit: 0.55\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess and resize image\n",
    "def process_image(image, size=(244, 244)):\n",
    "    try:\n",
    "        # Resize the image\n",
    "        image_resized = image.resize(size)\n",
    "        # Convert to numpy array\n",
    "        image_array = np.array(image_resized)\n",
    "        return image_array\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process image: {e}\")\n",
    "        return None\n",
    "\n",
    "# OCR function to extract text from the image\n",
    "def extract_text_from_image(image):\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from image: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to load images and apply OCR\n",
    "def load_images_with_ocr(df, image_dir, max_images, batch_size=100):\n",
    "    total_images = len(df)\n",
    "    batches = (total_images + batch_size - 1) // batch_size  # Calculate number of batches\n",
    "    images = []\n",
    "    image_arrays = []\n",
    "    all_images = []\n",
    "    df = df.head(max_images)\n",
    "\n",
    "    for batch_index in range(batches):\n",
    "        batch_df = df.iloc[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
    "        successfully_loaded = 0\n",
    "        skipped_files = 0\n",
    "        total_mapped = 0\n",
    "\n",
    "        for index, row in batch_df.iterrows():\n",
    "            total_mapped += 1\n",
    "            # Extract the filename from the image link\n",
    "            image_filename = row['image_link'].split('/')[-1]\n",
    "            image_path = os.path.join(image_dir, image_filename)\n",
    "            image_path = image_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # Load the image if it exists, else append None\n",
    "            if os.path.exists(image_path):\n",
    "                try:\n",
    "                    with Image.open(image_path) as img:\n",
    "                        # Resize image\n",
    "                        image_array = process_image(img)\n",
    "                        image_arrays.append(image_array)\n",
    "\n",
    "                        images.append(img.copy())  # Copy the image to avoid keeping the file open\n",
    "                        successfully_loaded += 1\n",
    "                except (UnidentifiedImageError, OSError) as e:\n",
    "                    print(f\"Warning: Error opening image file {image_path}: {e}\")\n",
    "                    images.append(None)  # Append None if the image is invalid or corrupted\n",
    "                    skipped_files += 1\n",
    "            else:\n",
    "                print(f\"Warning: Image file {image_path} does not exist. Skipping...\")\n",
    "                images.append(None)\n",
    "                skipped_files += 1\n",
    "        all_images.extend(images)\n",
    "        print(f\"Total images mapped: {total_mapped}\")\n",
    "        print(f\"Successfully loaded images: {successfully_loaded}\")\n",
    "        print(f\"Skipped images: {skipped_files}\")\n",
    "\n",
    "    return images, image_arrays\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(r'C:\\Users\\Hrushikesh\\OneDrive\\Desktop\\ML Hackathon\\student_resource 3\\dataset\\Book1.csv')\n",
    "train_image_dir = r'C:\\Users\\Hrushikesh\\OneDrive\\Desktop\\ML Hackathon\\student_resource 3\\downloaded_images_2\\downloaded_images_2'\n",
    "MAX_IMAGES = 100\n",
    "\n",
    "# Load training images\n",
    "train_images, train_arrays = load_images_with_ocr(train_df, train_image_dir, MAX_IMAGES, 100)\n",
    "\n",
    "# Add images and arrays to the dataset\n",
    "mapped_train_dataset = train_df.head(MAX_IMAGES).copy()\n",
    "mapped_train_dataset['Image'] = train_images\n",
    "mapped_train_dataset['Image_Arrays'] = train_arrays\n",
    "\n",
    "# Split 'entity_value' into numeric value and unit\n",
    "mapped_train_dataset[['entity_number', 'entity_unit']] = mapped_train_dataset['entity_value'].str.extract(r'([0-9.]+)\\s*(\\w+)')\n",
    "mapped_train_dataset['entity_number'] = pd.to_numeric(mapped_train_dataset['entity_number'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values in 'entity_number' after conversion\n",
    "mapped_train_dataset = mapped_train_dataset.dropna(subset=['entity_number'])\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(mapped_train_dataset[['entity_value', 'entity_number', 'entity_unit']])\n",
    "\n",
    "# One-hot encode the 'entity_name' and 'entity_unit' columns\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Encode entity_name\n",
    "categorical_column = mapped_train_dataset[['entity_name']]\n",
    "column_encoded = encoder.fit_transform(categorical_column)\n",
    "column_encoded_df = pd.DataFrame(column_encoded, columns=encoder.get_feature_names_out(['entity_name']))\n",
    "mapped_train_dataset = pd.concat([mapped_train_dataset.drop(columns=['entity_name']), column_encoded_df], axis=1)\n",
    "\n",
    "# Encode entity_unit\n",
    "categorical_column = mapped_train_dataset[['entity_unit']]\n",
    "column_encoded = encoder.fit_transform(categorical_column)\n",
    "column_encoded_df = pd.DataFrame(column_encoded, columns=encoder.get_feature_names_out(['entity_unit']))\n",
    "mapped_train_dataset = pd.concat([mapped_train_dataset.drop(columns=['entity_unit']), column_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler_entity_number = MinMaxScaler()\n",
    "# Fit and transform the entity_number column\n",
    "mapped_train_dataset['entity_number'] = scaler_entity_number.fit_transform(mapped_train_dataset[['entity_number']])\n",
    "\n",
    "\n",
    "# Convert train_arrays (list) to a NumPy array and flatten the image arrays\n",
    "train_arrays = np.array(train_arrays)\n",
    "train_image_arrays_flat = train_arrays.reshape(train_arrays.shape[0], -1)\n",
    "\n",
    "print(mapped_train_dataset.columns.tolist())\n",
    "\n",
    "# Define target variables\n",
    "target_number = mapped_train_dataset['entity_number']\n",
    "target_unit = mapped_train_dataset.filter(regex='^entity_unit_')\n",
    "\n",
    "# Drop target columns from features\n",
    "col_to_drop = ['image_link', 'group_id', 'entity_value', 'Image', 'Image_Arrays', 'entity_number', 'entity_unit']\n",
    "mapped_train_dataset_dropped = mapped_train_dataset.drop(columns=col_to_drop, errors='ignore')\n",
    "\n",
    "# Combine features and apply PCA\n",
    "try:\n",
    "    # Dimensionality reduction using PCA\n",
    "    n_components = min(1000, train_image_arrays_flat.shape[0], train_image_arrays_flat.shape[1])\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_image_features = pca.fit_transform(train_image_arrays_flat)\n",
    "    train_features = np.hstack((reduced_image_features, mapped_train_dataset_dropped.to_numpy()))\n",
    "    print(\"Shape of train_features:\", train_features.shape)\n",
    "except Exception as e:\n",
    "    print(f\"Error combining features: {e}\")\n",
    "\n",
    "# Ensure train_features is a numeric NumPy array\n",
    "try:\n",
    "    train_features = np.array(train_features, dtype=float)\n",
    "    print(\"Type of train_features:\", type(train_features))\n",
    "    print(\"Shape of train_features:\", train_features.shape)\n",
    "except Exception as e:\n",
    "    print(f\"Error converting to float: {e}\")\n",
    "\n",
    "# Check for NaNs and Infs\n",
    "if np.issubdtype(train_features.dtype, np.number):\n",
    "    print(\"NaNs in train_features:\", np.any(np.isnan(train_features)))\n",
    "    print(\"Infs in train_features:\", np.any(np.isinf(train_features)))\n",
    "else:\n",
    "    print(\"train_features contains non-numeric data.\")\n",
    "\n",
    "# Replace NaNs with a specific value (e.g., 0)\n",
    "train_features = np.nan_to_num(train_features)\n",
    "\n",
    "# Proceed with train/test split and model fitting\n",
    "X_train, X_valid, y_train_number, y_valid_number = train_test_split(train_features, target_number, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train_unit, y_valid_unit = train_test_split(train_features, target_unit, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate models\n",
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "regressor.fit(X_train, y_train_number)\n",
    "y_pred_number = regressor.predict(X_valid)\n",
    "print(\"Mean Squared Error for entity_number:\", mean_squared_error(y_valid_number, y_pred_number))\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train_unit)\n",
    "y_pred_unit = classifier.predict(X_valid)\n",
    "print(\"Accuracy for entity_unit:\", accuracy_score(y_valid_unit, y_pred_unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>Image</th>\n",
       "      <th>Image_Arrays</th>\n",
       "      <th>entity_number</th>\n",
       "      <th>entity_name_item_volume</th>\n",
       "      <th>entity_name_item_weight</th>\n",
       "      <th>entity_name_voltage</th>\n",
       "      <th>entity_name_wattage</th>\n",
       "      <th>...</th>\n",
       "      <th>entity_unit_cup</th>\n",
       "      <th>entity_unit_gallon</th>\n",
       "      <th>entity_unit_gram</th>\n",
       "      <th>entity_unit_kilogram</th>\n",
       "      <th>entity_unit_milligram</th>\n",
       "      <th>entity_unit_millilitre</th>\n",
       "      <th>entity_unit_ounce</th>\n",
       "      <th>entity_unit_pound</th>\n",
       "      <th>entity_unit_volt</th>\n",
       "      <th>entity_unit_watt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1600x1600...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0.099937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>1.0 cup</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1200x1200...</td>\n",
       "      <td>[[[155, 190, 209], [153, 188, 207], [153, 188,...</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1081x1081...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1081x1081...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>1400 milligram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1500x1500...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0.279950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71XK5d3Oh9...</td>\n",
       "      <td>416664</td>\n",
       "      <td>49.0 watt</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=2560x2560...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61kyBEJYDe...</td>\n",
       "      <td>459516</td>\n",
       "      <td>500 milligram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1500x1500...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0.099937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71uQmsTESv...</td>\n",
       "      <td>459516</td>\n",
       "      <td>500 milligram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1500x1500...</td>\n",
       "      <td>[[[253, 253, 253], [254, 254, 254], [254, 254,...</td>\n",
       "      <td>0.099937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71jG8BOi4W...</td>\n",
       "      <td>241608</td>\n",
       "      <td>16.0 gram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=1600x1600...</td>\n",
       "      <td>[[[227, 228, 230], [228, 229, 231], [228, 229,...</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61390hosjF...</td>\n",
       "      <td>308856</td>\n",
       "      <td>8 kilogram</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=984x1000 ...</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_link  group_id  \\\n",
       "0   https://m.media-amazon.com/images/I/61I9XdN6OF...    748919   \n",
       "1   https://m.media-amazon.com/images/I/71gSRbyXmo...    916768   \n",
       "2   https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516   \n",
       "3   https://m.media-amazon.com/images/I/612mrlqiI4...    459516   \n",
       "4   https://m.media-amazon.com/images/I/617Tl40LOX...    731432   \n",
       "..                                                ...       ...   \n",
       "95  https://m.media-amazon.com/images/I/71XK5d3Oh9...    416664   \n",
       "96  https://m.media-amazon.com/images/I/61kyBEJYDe...    459516   \n",
       "97  https://m.media-amazon.com/images/I/71uQmsTESv...    459516   \n",
       "98  https://m.media-amazon.com/images/I/71jG8BOi4W...    241608   \n",
       "99  https://m.media-amazon.com/images/I/61390hosjF...    308856   \n",
       "\n",
       "      entity_value                                              Image  \\\n",
       "0       500.0 gram  <PIL.Image.Image image mode=RGB size=1600x1600...   \n",
       "1          1.0 cup  <PIL.Image.Image image mode=RGB size=1200x1200...   \n",
       "2       0.709 gram  <PIL.Image.Image image mode=RGB size=1081x1081...   \n",
       "3       0.709 gram  <PIL.Image.Image image mode=RGB size=1081x1081...   \n",
       "4   1400 milligram  <PIL.Image.Image image mode=RGB size=1500x1500...   \n",
       "..             ...                                                ...   \n",
       "95       49.0 watt  <PIL.Image.Image image mode=RGB size=2560x2560...   \n",
       "96   500 milligram  <PIL.Image.Image image mode=RGB size=1500x1500...   \n",
       "97   500 milligram  <PIL.Image.Image image mode=RGB size=1500x1500...   \n",
       "98       16.0 gram  <PIL.Image.Image image mode=RGB size=1600x1600...   \n",
       "99      8 kilogram  <PIL.Image.Image image mode=RGB size=984x1000 ...   \n",
       "\n",
       "                                         Image_Arrays  entity_number  \\\n",
       "0   [[[255, 255, 255], [255, 255, 255], [255, 255,...       0.099937   \n",
       "1   [[[155, 190, 209], [153, 188, 207], [153, 188,...       0.000130   \n",
       "2   [[[255, 255, 255], [255, 255, 255], [255, 255,...       0.000072   \n",
       "3   [[[255, 255, 255], [255, 255, 255], [255, 255,...       0.000072   \n",
       "4   [[[255, 255, 255], [255, 255, 255], [255, 255,...       0.279950   \n",
       "..                                                ...            ...   \n",
       "95  [[[255, 255, 255], [255, 255, 255], [255, 255,...       0.009731   \n",
       "96  [[[255, 255, 255], [255, 255, 255], [255, 255,...       0.099937   \n",
       "97  [[[253, 253, 253], [254, 254, 254], [254, 254,...       0.099937   \n",
       "98  [[[227, 228, 230], [228, 229, 231], [228, 229,...       0.003130   \n",
       "99  [[[255, 255, 255], [255, 255, 255], [255, 255,...       0.001530   \n",
       "\n",
       "    entity_name_item_volume  entity_name_item_weight  entity_name_voltage  \\\n",
       "0                       0.0                      1.0                  0.0   \n",
       "1                       1.0                      0.0                  0.0   \n",
       "2                       0.0                      1.0                  0.0   \n",
       "3                       0.0                      1.0                  0.0   \n",
       "4                       0.0                      1.0                  0.0   \n",
       "..                      ...                      ...                  ...   \n",
       "95                      0.0                      0.0                  0.0   \n",
       "96                      0.0                      1.0                  0.0   \n",
       "97                      0.0                      1.0                  0.0   \n",
       "98                      0.0                      1.0                  0.0   \n",
       "99                      0.0                      1.0                  0.0   \n",
       "\n",
       "    entity_name_wattage  ...  entity_unit_cup  entity_unit_gallon  \\\n",
       "0                   0.0  ...              0.0                 0.0   \n",
       "1                   0.0  ...              1.0                 0.0   \n",
       "2                   0.0  ...              0.0                 0.0   \n",
       "3                   0.0  ...              0.0                 0.0   \n",
       "4                   0.0  ...              0.0                 0.0   \n",
       "..                  ...  ...              ...                 ...   \n",
       "95                  1.0  ...              0.0                 0.0   \n",
       "96                  0.0  ...              0.0                 0.0   \n",
       "97                  0.0  ...              0.0                 0.0   \n",
       "98                  0.0  ...              0.0                 0.0   \n",
       "99                  0.0  ...              0.0                 0.0   \n",
       "\n",
       "    entity_unit_gram  entity_unit_kilogram  entity_unit_milligram  \\\n",
       "0                1.0                   0.0                    0.0   \n",
       "1                0.0                   0.0                    0.0   \n",
       "2                1.0                   0.0                    0.0   \n",
       "3                1.0                   0.0                    0.0   \n",
       "4                0.0                   0.0                    1.0   \n",
       "..               ...                   ...                    ...   \n",
       "95               0.0                   0.0                    0.0   \n",
       "96               0.0                   0.0                    1.0   \n",
       "97               0.0                   0.0                    1.0   \n",
       "98               1.0                   0.0                    0.0   \n",
       "99               0.0                   1.0                    0.0   \n",
       "\n",
       "    entity_unit_millilitre  entity_unit_ounce  entity_unit_pound  \\\n",
       "0                      0.0                0.0                0.0   \n",
       "1                      0.0                0.0                0.0   \n",
       "2                      0.0                0.0                0.0   \n",
       "3                      0.0                0.0                0.0   \n",
       "4                      0.0                0.0                0.0   \n",
       "..                     ...                ...                ...   \n",
       "95                     0.0                0.0                0.0   \n",
       "96                     0.0                0.0                0.0   \n",
       "97                     0.0                0.0                0.0   \n",
       "98                     0.0                0.0                0.0   \n",
       "99                     0.0                0.0                0.0   \n",
       "\n",
       "    entity_unit_volt  entity_unit_watt  \n",
       "0                0.0               0.0  \n",
       "1                0.0               0.0  \n",
       "2                0.0               0.0  \n",
       "3                0.0               0.0  \n",
       "4                0.0               0.0  \n",
       "..               ...               ...  \n",
       "95               0.0               1.0  \n",
       "96               0.0               0.0  \n",
       "97               0.0               0.0  \n",
       "98               0.0               0.0  \n",
       "99               0.0               0.0  \n",
       "\n",
       "[100 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
